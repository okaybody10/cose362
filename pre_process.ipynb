{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sung/anaconda3/envs/cose362/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from kobert_transformers import get_tokenizer\n",
    "from gluonnlp.data import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = tokenizer('뽀로로는 남극에 사는 펭귄이 아니다.', padding=True, truncation=True) # Has Input_ids, token_type_ids, attention_mask\n",
    "res = tokenizer.convert_ids_to_tokens(tok['input_ids'])\n",
    "print(type(tok['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PS': 1, 'B-FD': 2, 'B-TR': 3, 'B-AF': 4, 'B-OG': 5, 'B-LC': 6, 'B-CV': 7, 'B-DT': 8, 'B-TI': 10, 'B-QT': 11, 'B-EV': 12, 'B-AM': 13, 'B-PT': 14, 'B-MT': 15, 'B-TM': 16, 'I-PS': 17, 'I-FD': 18, 'I-TR': 19, 'I-AF': 20, 'I-OG': 21, 'I-LC': 22, 'I-CV': 23, 'I-DT': 24, 'I-TI': 26, 'I-QT': 27, 'I-EV': 28, 'I-AM': 29, 'I-PT': 30, 'I-MT': 31, 'I-TM': 32} {0: 'O', 1: 'B-PS', 2: 'B-FD', 3: 'B-TR', 4: 'B-AF', 5: 'B-OG', 6: 'B-LC', 7: 'B-CV', 8: 'B-DT', 9: 'B-TI', 10: 'B-TI', 11: 'B-QT', 12: 'B-EV', 13: 'B-AM', 14: 'B-PT', 15: 'B-MT', 16: 'B-TM', 17: 'I-PS', 18: 'I-FD', 19: 'I-TR', 20: 'I-AF', 21: 'I-OG', 22: 'I-LC', 23: 'I-CV', 24: 'I-DT', 25: 'I-TI', 26: 'I-TI', 27: 'I-QT', 28: 'I-EV', 29: 'I-AM', 30: 'I-PT', 31: 'I-MT', 32: 'I-TM'}\n"
     ]
    }
   ],
   "source": [
    "label_list = ['PS', 'FD', 'TR', 'AF', 'OG', 'LC', 'CV', 'DT', 'TI', 'TI', 'QT', 'EV', 'AM', 'PT', 'MT', \"TM\"] \n",
    "label_fin = ['O']\n",
    "label_fin += ['B-' + i for i in label_list]\n",
    "label_fin += ['I-' + i for i in label_list]\n",
    "label_to_idx = {label: idx for idx, label in enumerate(label_fin)}\n",
    "idx_to_label = {idx: label for idx, label in enumerate(label_fin)}\n",
    "print(label_to_idx, idx_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We will return the label of given words, using the ne_lists\n",
    "We use BIO-tagging\n",
    "'''\n",
    "def tagging(words: List[str], ne_lists: List[Dict[str, Any]]) -> List[str] :\n",
    "    results = [i if i in ['[CLS]', '[SEP]', '[PAD]'] else 'O' for i in words] # If token is not Special, initialize 'O' tag\n",
    "    ps_words = [i.replace('##', '').replace('▁','') for i in words]\n",
    "    ne_cnt = len(ne_lists)\n",
    "    ne_idx = -1\n",
    "    ne_label = 0\n",
    "\n",
    "    for idx, word in enumerate(ps_words) :\n",
    "        if results[idx] != 'O' or word == '' or word == '[UNK]':\n",
    "            continue\n",
    "        if word == '[UNK]' :\n",
    "            continue\n",
    "        # Now condition check\n",
    "        if ne_idx >= 0 : \n",
    "            nw_word = ne_lists[ne_idx]['form'][ne_label:]\n",
    "        else :\n",
    "            nw_word = ''\n",
    "\n",
    "        # I-tag condition\n",
    "        if (len(nw_word) > 0) & (nw_word.startswith(word)) & (results[idx-1][0] == 'B' or results[idx-1][0] == 'I') :\n",
    "            results[idx] = 'I-' + ne_lists[ne_idx]['label'][:2]\n",
    "            ne_label += len(word)\n",
    "        else : # B-tag condition\n",
    "            back_idx = ne_idx\n",
    "            back_label = ne_label\n",
    "            while ne_idx + 1 < ne_cnt :\n",
    "                ne_idx += 1\n",
    "                ne_label = 0\n",
    "                nw_word = ne_lists[ne_idx]['form']\n",
    "                if (len(nw_word) > 0) & (nw_word.startswith(word)) :\n",
    "                    results[idx] = 'B-' + ne_lists[ne_idx]['label'][:2]\n",
    "                    ne_label += len(word)\n",
    "                    break\n",
    "            if ne_idx + 1 == ne_cnt and ne_label == 0:\n",
    "                ne_idx = back_idx\n",
    "                ne_label = back_label\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁태', '안', '군의', '회', ',', '▁20', '19', '년', '‘', '군', '민', '중심', '’', '의', '정', '성과', '▁빛', '났다', '!', '[SEP]']\n",
      "['[CLS]', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'B-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"태안군의회, 2019년‘군민중심’의정성과 빛났다!\"\n",
    "ne = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"form\": \"태안군의회\",\n",
    "            \"label\": \"OGG_POLITICS\",\n",
    "            \"begin\": 0,\n",
    "            \"end\": 5\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"form\": \"2019년\",\n",
    "            \"label\": \"DT_YEAR\",\n",
    "            \"begin\": 7,\n",
    "            \"end\": 12\n",
    "        }\n",
    "]\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "tok = tokenizer(sentence, padding=True, truncation=True) # Has Input_ids, token_type_ids, attention_mask\n",
    "tokens_word = tokenizer.convert_ids_to_tokens(tok['input_ids'])\n",
    "print(tokens_word, tagging(tokens_word, ne), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json loads & dataframe preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_files(path='./dataset/NLNE2202211219.json') :\n",
    "    with open(path, \"r\") as f :\n",
    "        bef_data = json.load(f)\n",
    "\n",
    "    bef_data = bef_data['document']\n",
    "\n",
    "    df_tot = pd.DataFrame(columns=['form', 'NE'])\n",
    "\n",
    "    for r in bef_data :\n",
    "        df_tot = df_tot.append(pd.DataFrame.from_records(r['sentence'], columns=['form', 'NE']))\n",
    "\n",
    "    df_tot.dropna(how='any', inplace=True)\n",
    "\n",
    "    return df_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "form                          태안군의회, 2019년‘군민중심’의정성과 빛났다!\n",
       "NE      [{'id': 1, 'form': '태안군의회', 'label': 'OGG_POLI...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = load_files()\n",
    "tt.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_df(data: List[Any]) -> pd.DataFrame:\n",
    "#     return pd.DataFrame.from_records(data['sentence'], columns=['form'])\n",
    "# ex = bef_data[0]\n",
    "# ex = ex['sentence']\n",
    "# print(type(ex), ex[1], sep='\\n')\n",
    "# df = pd.DataFrame.from_records(ex, columns=['form', 'NE'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Define DataLoader, with tokenizer\n",
    "# Have to define collect_fn, to gather attention mask and another information\n",
    "# tok = tokenizer('뽀로로는 남극에 사는 펭귄이 아니다.', padding=True, truncation=True) # Has Input_ids, token_type_ids, attention_mask\n",
    "# tokenizer.convert_ids_to_tokens(tok['input_ids'])\n",
    "df = load_files()\n",
    "texts = df['form'].to_list()\n",
    "ne = df['NE'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset) :\n",
    "    def __init__(self, texts, labels, tokenizer, max_len = 256) -> None:\n",
    "        self.tokenizer = tokenizer \n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index) -> Any:\n",
    "        # tokenizer\n",
    "        input = self.texts[index]\n",
    "        sentence = self.tokenizer(input, padding = 'max_length', truncation = True, max_length = self.max_len) # Input_ids, token_type_ids, attention_mask\n",
    "        tags = tagging(self.tokenizer.convert_ids_to_tokens(sentence['input_ids']), self.labels[index])\n",
    "        convert_tags = [-100 if i in ['[CLS]', '[SEP]', '[PAD]'] else label_to_idx[i] for i in tags]\n",
    "        return {\n",
    "            'sentence' : input, # str\n",
    "            'input_ids' : torch.tensor(sentence['input_ids'], dtype=torch.long).to(devices),\n",
    "            'token_type_id' : torch.tensor(sentence['token_type_ids'], dtype=torch.long).to(devices),\n",
    "            'attention_mask' : torch.tensor(sentence['attention_mask'], dtype=torch.long).to(devices),\n",
    "            'labels' : torch.tensor(convert_tags, dtype=torch.long).to(devices)\n",
    "        } # Collect_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_ne, test_ne = train_test_split(texts, ne, test_size=0.2, random_state=42)\n",
    "test_dataset = CustomDataset(test_texts, test_ne, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'sentence': ['“위기청소년들에게 방역키트 드립니다.”', '한편 이번 임시회에서 강선구 의원이 대표 발의한 ‘예산군 긴급 생활안정 지원 조례안’과 예산군수가 제출한 ‘예산군 소상공인 지원조례 일부개정조례안’, ‘예산군 근로자 권리보호 및 증진 조례안’의 의결로 감염병 등 긴급 상황 발생으로 매출 감소, 실직, 휴직 등으로 어려움을 겪고 있는 군민과 생계에 어려움은 있으나 다른 법령에 따른 공적지원을 받지 못하는 군민의 생활안정 지원에 필요한 근거가 마련되었다.', '특히, 코로나19로 추진이 어려워진 ‘글로벌인재 해외연수’에 관해 학생들이 모두 차별없이 지속적으로 지원받을 수 있는 방향으로 대안이 마련되면 좋겠다는 것에 뜻을 모았다.', '바이오헬스는 ICT 산업 이후의 차세대 주력산업으로 꼽히지만 기본적인 용어부터가 어려운 탓에 일반인이 접근하기엔 쉽지 않은 장벽이 존재한다.', '최악의 경우, 수능 전날 진단검사를 받은 뒤 밤늦게 확진이나 자가격리 통보를 받는 수험생이 생길 수 있다.', '경남 남해군은 코로나 19로 인한 지역경제 침체를 극복하고 군민의 안전을 확보하기 위해 상반기 재난관리 및 예방사업에 대한 신속한 예산 집행으로 지역경제 활성화에 속도를 내겠다고 18일 밝혔다.', '정두수 전국가요제는 2017년까지 ‘하동 섬진강 전국가요제’로 치러졌으나 정두수 선생을 추모하고 가요제의 위상을 높여 예술의 고장 하동을 널리 알리고 참신한 신인을 발굴하고자 2018년 명칭을 바꿨다.', '제8대 대전시의회 후반기 의장 선출과 관련한 더불어민주당 내 집안싸움이 24일 4차 비공개 간담회를 통해 마침표를 찍을 전망이다.', '올해는 ▲내항동 GS 주유소부터 요암동 일원 1공구 3.2km ▲요암동부터 신흑동 흑포삼거리까지 2공구 2.5km ▲흑포삼거리부터 신흑동 일원 3공구 4km ▲신흑동 일원 1km ▲5~6공구 지역 정압기 2개 설치 등 모두 6개 공구 10.7km의 주 관로를 매설하게 되며, 이르면 연말부터 아파트 등 공동주택과 한화콘도에는 도시가스를 공급받을 수 있게 된다.', '평택해양경찰서(서장 이상인)는 8일 당진 및 서산 해상에서 수중레저사업 등록 없이 잠수 장비를 빌려주고 수산물을 불법 포획하도록 한 A 모씨(남, 51세)를 수중 레저 활동의 안전 및 활성화 등에 관한 법률(약칭 : 수중레저법) 등 위반 혐의로 검찰에 불구속 송치했다.', '청약 접수의 경우 오는 31일 특별공급을 시작으로 9월 1일 1순위, 2일 2순위 청약 접수를 진행할 예정이다.‘양주 옥정신도시 3차 노블랜드 에듀포레’는 지하 2층~지상 최고 37층, 총 8개동에 전용면적 75㎡ 502세대, 84㎡ 584세대, 전체 1086가구로 조성되는 2020년 양주 옥정신도시 마지막 브랜드 아파트이다.', '인천항만공사 이정행 운영부문 부사장은 “불안정한 대외 환경속에서도 수출에 힘쓰고 있는 여러 업·단체에 수익과 성장이 돌아갈 수 있도록 더욱 노력하겠다”면서 “앞으로도 수출 활성화에 기여할 수 있는 다양한 인센티브 정책을 발굴해 나갈 것”이라고 밝혔다.', '뉴욕, 런던, 파리, 홍콩 등 세계적인 도시에서 열리고 있다.', '중소벤처기업부는 선정기업에 해외마케팅 지원(바우처, 4년간 2억 원) 및 기술개발사업 우대 선정을 통해 해외진출과 신제품 개발을 촉진하고, 부산시는 전용지원프로그램(기업당 2000만 원 내외)을 통해 사업화를 지원한다.', '시는 다음 달 초까지 농림축산식품부가 국제농기계자재박람회 개최 여부를 결정할 것으로 예상하고 있다.', '중구의 한 중소기업 인사팀 관계자는 “기업 측에서는 가입 이후 관리 등 한정된 인력 내에서 업무가 가중될 것이라는 인식이 있다”며 “어떤 중소기업은 ‘청년내일채움공제’에 관해서만 맡는 인력도 있다”고 전했다.', '정 총리는 그러면서 이는 “다른 나라보다 먼저 위기를 겪었고 또 극단적인 봉쇄 없이도 성공적으로 극복했기에, K-방역에 이어 우리의 새로운 일상에도 세계가 주목하고 있다”고 설명했다.', '특히 우리나라의 남부지방이 아열대 기후로 점진적으로 변화함에 따라 기후변화에 대응해 아열대 과수를 비롯한 신소득 과수작물의 재배 환경을 개선하고, 재배규모 확대를 위해 기후온난화 대응작물 시범사업 등 3개 사업에 2억 1000만 원의 사업비를 지원한다.', '기존 일요일에는 운영하지 않던 수소충전소를 확대 운영함으로써, 1년 365일 어느 때나 수소충전이 가능해진 셈이다.', '섬의 중요성과 가치를 제고하고 국민에게 이를 알리기 위해 2018년 정부는 8월 8일을 ‘섬의 날’로 제정하고 2019. 8. 8일 제1회 섬의 날을 목포시에서 개최해 ‘섬’을 주제로 한 범정부 행사를 통해 섬에 대한 정부의 정책을 홍보했다.', '정 후보자는 “공직사회의 울타리를 넘어 현장의 목소리를 직접 듣겠다”면서 “스웨덴의 안정과 발전의 밑거름이 된 목요클럽과 같은 대화모델을 되살려 각 정당과 각계각층의 대표들을 정기적으로 만나겠다”고 약속했다.', '이날 기탁은 지난해 100만 원 성금 기탁에 이은 두 번째며, 성금은 현대자동차충주북부지점 전 직원이 지난해 하반기 동안 자동차를 판매하고 얻은 수익금 일부를 모아 마련됐다.', '이번 조례안 제정은 천안서북경찰서가 지난 9월 23일 시의회를 대상으로 보이스피싱 치안설명회를 개최해 보이스피싱 예방 필요성에 대한 공감대를 형성하고 제안함에 따라 이뤄졌다.', '여기에 의장 후보군으로 거론되는 이들의 전반기 부의장과 상임위원장 등을 맡은 이력을 강조하며 욕심과 오만을 갖고 의회 권력을 사유화시키려는 의도가 다분하다고 꼬집었다.', '하지만 중대본으로부터 전달받은 명단에는 예비신도인 신천지 교육생은 포함되지 않았다.', '권흥주 회장은 “봉사는 처음에는 누군가를 도와주기 위해 시작하지만 결국은 내가 얻는 것이 더 많다”며 “코로나 사태라고 연탄봉사를 걸렀으면 할머니가 큰 어려움을 겪었을 생각을 하니 참 잘했다는 생각이 든다” 고 말했다.', '이는 설 연휴 이후 발생하는 일시적인 매출 감소세가 아니라는 점에서 지역 백화점의 불안감은 장기화가 될 가능성이 높다.', '20일 민주당 소속 시의원들은 입장문을 통해 “지금 우리 보령시는 더 이상 코로나19 감염의 위험으로부터 청정지역이 아니다”면서 “감염의 경로가 불명확한 확진자까지 발생하는 심각한 상황에 처해 있다”고 우려했다.', '선승혜 관장이 취임한 2019년부터 시작된 ‘대전미술 다시쓰기’는 세 번째 기획전으로 1990년대를 다룬다.', '\"따뜻한 추석 이웃과 함께\" 농식품부 나눔 실천', '전남도청이 위탁 운영하는 농수축산물 온라인 쇼핑몰 ‘남도장터’와 ‘국민안내양TV’가 함께하는 영암의 농·특산물 홍보 방송은 영암의 상징인 월출산 ‘기(氣)찬랜드’에서 진행됐다.', '반면, 시립노인전문병원 건립과 남부권 응급의료 지원체계 구축은 보류 또는 부진사업으로 분류됐다.'], 'input_ids': tensor([[   2,  714, 7046,  ...,    1,    1,    1],\n",
      "        [   2, 4974, 3697,  ...,    1,    1,    1],\n",
      "        [   2, 4792,   46,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,  518, 5959,  ...,    1,    1,    1],\n",
      "        [   2, 4018, 5859,  ...,    1,    1,    1],\n",
      "        [   2, 2212,   46,  ...,    1,    1,    1]], device='cuda:0'), 'token_type_id': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    5,   21,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100]], device='cuda:0')}\n",
      "5\n",
      "{'sentence': ['농가부담 1%로 축산농가의 입식우 기반확충 사업에 탄력을 받을 전망이다.', '이어 송아량 의원은 “동북선 공사가 본격적으로 추진됨에 따라 서울시의회 교통위원으로서 공사 중 ‘교통소통대책 심의, 도로공사 신고, 도로굴착계획 심의, 도로점용허가’등과 관련절차에 관한 사항을 의정활동을 통해 동북선 공사로 인해 시민의 불편을 최소화 할 수 있도록 노력하겠다”라고 말했다.', '지난해 참가신청자 8000명에 이르는 중부권 최고의 마라톤 축제로 자리 잡은 공주백제마라톤 대회의 성공 개최를 위해 추경예산 확보에 주력하고, 체육발전과 공주시에 도움이 되는 전국 규모 대회도 적극 유치할 방침이다.', '도시공사는 이달 사업협약을 체결하고 내년부터 기본·실시설계에 들어갈 예정이다.', '국가 관광거점도시 전주의 대표 여행지인 전주한옥마을의 골목길 정취와 멋, 문화가 담긴 에세이가 출간됐다.', '학부모는 희망순위(1, 2, 3)별로 유치원에 접수하고, 희망순위별로 추첨이 이루어진다.', '시는 안전점검 기간 중 공무원과 민간전문가 등으로 편성된 합동점검반을 통해 3월 16일부터 20일까지 5일간 위험도가 높은 시설에 대한 표본점검을 실시하고, 파손 정도의 식별이 어렵거나 위험성이 높은 경우 민간전문가를 활용해 재해위험도 평가를 실시할 계획이다.', '시 관계자는 “민원이 발생하면서 1일부터 결제를 차단했다.', '염태영 수원시장은 “2021년, 수원시는 ‘시민 승리’를 향해 나아가겠다”고 18일 밝혔다.', '정부는 국방개혁2.0의 일환으로 장병복지 증대를 위해 평일 일과 이후 외출을 허용하는 ‘군 장병 외출제도’를 2018년 시범사업을 거쳐 지난해 2월부터 전국에 확대 시행해왔다.', '또한 약 4억 원의 설계 용역비를 절감하는 효과를 거둬 어려운 군 재정에도 도움이 될 전망이다.', '\"능률 올라\"-\"근무 한계\" 직장인 재택근무 평가 엇갈려', '시는 오는 10월 4일까지 △빈틈없는 코로나19 방역 △안전교통 대책 △물가 및 주민 생활 안정 △재난 사고 예방 및 대응 △취약·소외계층 위문 및 지원 △공직기강 확립 등 6대 분야 29개 과제를 추진할 방침이다.', '전담수송팀을 갖추고 중계수송을 실시하게 되면, 출동준비 및 이동시간을 줄일 수 있어 서울 기준으로 최대 5시간을 단축시키고, 운전자들의 피로도를 경감시키게 될 것으로 보여진다.', '충남대·한밭대 등 대전지역 국립대가 1학기 전면 원격수업으로 결정한 가운데 비대면 수업을 진행중인 대학들을 중심으로 등록금 환불 논의가 거세지고 있다.', '한편 유해발굴 사업 추진을 위한 자문단에는 최완규 원광대학교 고고미술사학과 교수와 하태규 전북대학교 사학과 교수, 홍성덕 전주대학교 역사문화콘텐츠학과 교수, 노용석 부경대학교 국제학부 교수, 이형우 전북대학교 고고문화인류학과 교수, 성홍제 ‘전주형무소 민간인 희생자’ 유족회장, 이인철 ‘6.25 민간인 희생자’ 조사연구회장이 참여한다.', '현재 도에서 내포에 혁신도시 지정을 추진 중인데 내포가 혁신도시로 지정되더라도 공공기관의 이전은 도내 균형발전을 고려해서 이루어져야 하며, 국가균형발전특별법에서 혁신도시시책을 추진할 때에는 ‘혁신도시 활성화 및 인근 지역과의 상생발전에 관한 사항’을 고려해야 한다고 한 만큼 충남 서북부권에 비해 상대적으로 저발전된 지역인 공주·부여·청양에 공공기관 이전이 필요하다”라고 강조했다.', '도시락 봉사에는 연수평화도서관, 개구리네한솥밥어린이식당, 연수구사랑나눔가족봉사단, 마을기업 다온공간 븟, 백암왕순대(청학동), 춘천닭갈비(선학동), 장금수부대찌개 등 마을공동체와 지역 음식점들이 참여했다.', '특히 지난해는 1973년 기상청 관측 이래 연평균기온과 연평균 최고기온이 가장 높은 해로 기록되기도 했다.', '녹색도시는 시민과 정부가 다 같이 노력하여야만 조성할 수 있다.', '한순기 충북도 기획관리실장 부임 100일', '세종 관광분야 스타트업 발굴…7월 27일까지 접수', '대나무를 소재로 한 사진전 죽림설화(竹林雪花)를 통해 인생을 반추했던 사진작가 원춘호가 이번에는 기와를 소재로 삼았다.', '그동안 대한치과의사협회를 중심으로 치의과학연구원 설립을 요구하는 목소리는 꾸준히 이어졌다.', '◆“반갑다 친구야” 아직은 걱정되지만 표정은 활짝', '산악인 엄홍길 대장과 드론운영팀, 방송사 기자 등 10명으로 구성된 KT 드론 수색팀도 이날 7시43분부터 수색에 착수했다.', '한편 도는 경기도 재난기본소득 선불카드 분실 시 재발급이 가능하도록 지침을 변경했다.', '우리 시는 지역경제 활성화, 일자리 창출, 쾌적한 환경조성, 빈틈없이 복지확대 등을 통한 자연스러운 인구증가를 반드시 이뤄내겠다”고 밝혔다.', '김성도·김신열 부부가 1991년 11월 17일부터 서도에 거주했으며 김성도씨는 2018년 10월 21일 지병으로 별세했다.', '보령시는 지난 15일 시청 중회의실에서 김동일 시장 주재로 읍면동장 등 30여 명이 참석한 가운데 지방세 체납액 징수대책 보고회를 가졌다고 16일 밝혔다.', '특히 군은 2018년부터 정해진 소득을 초과하는 경우라도 군 자체 예산을 확보해 부부 모두 6개월 이상 관내에 거주하는 출산가정을 대상으로 확대 지원 중에  있으며, 2018년 122명을 지원했으나 2019년 12월 말 출생아 수 291명 중 178명(61.2%)에 대한 지원으로 전년 대비 56명이 증가한 성과를 거뒀다.', '‘가야문화권 조사·연구 및 정비사업’ 국정과제의 일환으로 문화재청에서 추진 중인 가야문화권 출토 중요 유물 지정조사 사업을 통해, 그동안 소외됐던 복천동 고분군의 출토유물이 그 가치를 인정받게 된 것이다.'], 'input_ids': tensor([[   2, 1507, 5330,  ...,    1,    1,    1],\n",
      "        [   2, 3716, 2869,  ...,    1,    1,    1],\n",
      "        [   2, 4306, 4428,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2, 2355, 6077,  ...,    1,    1,    1],\n",
      "        [   2, 4792, 1165,  ...,    1,    1,    1],\n",
      "        [   2,  712, 5330,  ...,    1,    1,    1]], device='cuda:0'), 'token_type_id': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    1,  ..., -100, -100, -100],\n",
      "        [-100,    8,    0,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100,    5,   21,  ..., -100, -100, -100],\n",
      "        [-100,    0,    5,  ..., -100, -100, -100],\n",
      "        [-100,    0,   16,  ..., -100, -100, -100]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for batch in test_loader :\n",
    "    if cnt > 1 :\n",
    "        break\n",
    "    cnt += 1\n",
    "    print(len(batch), batch, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_implement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
